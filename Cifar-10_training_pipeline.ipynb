{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccaf5880",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats\n",
    "\n",
    "\n",
    "This Notebook include:\n",
    "1.  Data preprocessing\n",
    "2.  Load train, validation and test datasets\n",
    "3.  Model define and training\n",
    "4.  Whole model Fine-Tuning\n",
    "5.  Predict test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5d82c",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing\n",
    "\n",
    "Define training transforms(with augmentaion) and validation transforms. This is because during testing, we want to evaluate the model's true performance on images that are \"original\" and consistent, rather than on randomly varied images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c16357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\83696\\.conda\\envs\\chatglm3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transforms defined successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define image size \n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Mean and std for ImageNet normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 1. Define transforms for training data (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),      # 1. Resize the image\n",
    "    transforms.RandomHorizontalFlip(),          # 2. Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(10),              # 3. Randomly rotate the image (+/- 10 degrees)\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), # 4. Apply slight color jitter\n",
    "    transforms.ToTensor(),                      # 5. Convert to PyTorch Tensor (scales to [0, 1])\n",
    "    transforms.Normalize(mean=mean, std=std)    # 6. Normalize the tensor\n",
    "])\n",
    "\n",
    "# 2. Define transforms for validation & test data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),      # 1. Resize the image\n",
    "    transforms.ToTensor(),                      # 2. Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=mean, std=std)    # 3. Normalize the tensor\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab33e0-0186-4e76-a048-139872047c77",
   "metadata": {},
   "source": [
    "### 2. Load train，validation and test datasets\n",
    "\n",
    "Creat two dataLoaders: one for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682fb351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Total Cifar-10 train images: 50000\n",
      "  -> Split into 45000 for training\n",
      "  -> Split into 5000 for validation\n",
      "Total Cifar-10 test images (holdout): 10000\n",
      "\n",
      "Successfully loaded 45000 training images and 5000 validation images and 10000 test images.\n",
      "\n",
      "  Checking DataLoader  \n",
      "Image batch shape: torch.Size([64, 3, 224, 224])\n",
      "Label batch shape: torch.Size([64])\n",
      "Label examples: tensor([5, 7, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "# 1. Define Data Paths \n",
    "DATA_DIR = './dataset' \n",
    "\n",
    "BATCH_SIZE = 64 \n",
    "\n",
    "# 2. Create Dataset Instances\n",
    "\n",
    "# Load the training set and apply training transforms\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_DIR, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Load the validation set and apply test transforms (no augmentation)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=DATA_DIR, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# 3. 从 \"full_train_dataset\" 中分割出 验证集 (Validation Set)\n",
    "VAL_SPLIT_SIZE = 5000 # 设定 5000 张图片用于验证\n",
    "TRAIN_SPLIT_SIZE = len(full_train_dataset) - VAL_SPLIT_SIZE # 剩余 45000 张用于训练\n",
    "train_subset, val_subset = random_split(\n",
    "    full_train_dataset, \n",
    "    [TRAIN_SPLIT_SIZE, VAL_SPLIT_SIZE],\n",
    "    generator=torch.Generator().manual_seed(42) # 保证分割可复现\n",
    ")\n",
    "\n",
    "# 4. Check Labels\n",
    "print(f\"Total Cifar-10 train images: {len(full_train_dataset)}\")\n",
    "print(f\"  -> Split into {len(train_subset)} for training\")\n",
    "print(f\"  -> Split into {len(val_subset)} for validation\")\n",
    "print(f\"Total Cifar-10 test images (holdout): {len(test_dataset)}\")\n",
    "\n",
    "# 5. Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # Shuffle the training data\n",
    "    num_workers=4  # Use multiple processes to load data (set to 0 on Windows if errors occur)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, # Validation data does not need to be shuffled\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(train_subset)} training images and {len(val_subset)} validation images and {len(test_dataset)} test images.\")\n",
    "\n",
    "# 6. Check one batch\n",
    "print(\"\\n  Checking DataLoader  \")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Image batch shape: {images.shape}\") # [BATCH_SIZE, 3, 224, 224]\n",
    "print(f\"Label batch shape: {labels.shape}\") # [BATCH_SIZE]\n",
    "print(f\"Label examples: {labels[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fac2c-766a-4975-a485-d625686c7b09",
   "metadata": {},
   "source": [
    "### 3. Model define and training\n",
    "During the model training phase, we used transfer learning, loading a pre-trained ResNet-34 model. We trained only the last layer of this pre-trained model (ResNet-34) to quickly complete the cat and dog classification task. The code loops 10 times, evaluating the performance with a validation set after each loop, and finally saving the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e6ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Class mapping: {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "\n",
      "  Starting Training (Feature Extraction)  \n",
      "Epoch 1/10 [160s]\n",
      "  Train Loss: 0.9402 Acc: 0.6958\n",
      "  Val   Loss: 0.5548 Acc: 0.8120\n",
      "  New best model saved (Acc: 0.8120)\n",
      "Epoch 2/10 [162s]\n",
      "  Train Loss: 0.6906 Acc: 0.7645\n",
      "  Val   Loss: 0.5121 Acc: 0.8242\n",
      "  New best model saved (Acc: 0.8242)\n",
      "Epoch 3/10 [163s]\n",
      "  Train Loss: 0.6702 Acc: 0.7694\n",
      "  Val   Loss: 0.5203 Acc: 0.8146\n",
      "Epoch 4/10 [158s]\n",
      "  Train Loss: 0.6490 Acc: 0.7768\n",
      "  Val   Loss: 0.4896 Acc: 0.8298\n",
      "  New best model saved (Acc: 0.8298)\n",
      "Epoch 5/10 [157s]\n",
      "  Train Loss: 0.6372 Acc: 0.7810\n",
      "  Val   Loss: 0.4921 Acc: 0.8276\n",
      "Epoch 6/10 [169s]\n",
      "  Train Loss: 0.6312 Acc: 0.7830\n",
      "  Val   Loss: 0.4733 Acc: 0.8348\n",
      "  New best model saved (Acc: 0.8348)\n",
      "Epoch 7/10 [191s]\n",
      "  Train Loss: 0.6304 Acc: 0.7806\n",
      "  Val   Loss: 0.4793 Acc: 0.8340\n",
      "Epoch 8/10 [185s]\n",
      "  Train Loss: 0.6252 Acc: 0.7854\n",
      "  Val   Loss: 0.4734 Acc: 0.8302\n",
      "Epoch 9/10 [189s]\n",
      "  Train Loss: 0.6238 Acc: 0.7864\n",
      "  Val   Loss: 0.4877 Acc: 0.8288\n",
      "Epoch 10/10 [190s]\n",
      "  Train Loss: 0.6154 Acc: 0.7871\n",
      "  Val   Loss: 0.5108 Acc: 0.8170\n",
      "\n",
      "Training complete. Best validation accuracy: 0.8348\n",
      "Best model weights loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# 1. Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Load pre-trained model (ResNet-34)\n",
    "# Download ResNet-34 with weights pre-trained on ImageNet\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 3. Freeze all pre-trained layers\n",
    "# Set requires_grad = False to stop gradients from flowing to these layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 4. Replace the final layer (classifier)\n",
    "# Get the number of input features for the original final layer ('fc')\n",
    "num_ftrs = model.fc.in_features \n",
    "\n",
    "# Replace it with a new Linear layer\n",
    "# Output features = 1 (for binary classification: 0=cat, 1=dog)\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Move the new model structure to the selected device (GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Define Loss Function and Optimizer\n",
    "# Loss Function: BCEWithLogitsLoss\n",
    "# This is ideal for binary classification. It combines a Sigmoid layer\n",
    "# with Binary Cross Entropy loss for better numerical stability.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Adam\n",
    "# IMPORTANT: We only pass the parameters of the new final layer\n",
    "# to the optimizer. Only this layer will be trained.\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Get the class index mapping (from the previous cell) for reference\n",
    "# We expect {'cat': 0, 'dog': 1}\n",
    "class_to_idx = full_train_dataset.class_to_idx\n",
    "print(f\"Class mapping: {class_to_idx}\")\n",
    "\n",
    "\n",
    "# 6. Training and Validation Loop\n",
    "NUM_EPOCHS = 10 # Number of times to loop through the entire training dataset\n",
    "best_val_acc = 0.0 # Track the best validation accuracy achieved\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Track the weights of the best model\n",
    "\n",
    "print(\"\\n  Starting Training (Feature Extraction)  \")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #   Training Phase  \n",
    "    model.train() # Set model to training mode (enables dropout, etc.)\n",
    "    val_subset.dataset.transform = train_transform\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Move data and labels to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = labels.to(device) \n",
    "        \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: get raw model output (logits)\n",
    "        outputs = model(inputs) \n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate predictions (0 or 1)\n",
    "        # 1. Apply sigmoid to logits (0 to 1 probability)\n",
    "        # 2. Threshold at 0.5 to get True/False\n",
    "        # 3. Convert to float (0.0 or 1.0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Backpropagation (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Update optimizer (only for model.fc weights)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate statistics for this epoch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_subset)\n",
    "    epoch_acc = running_corrects.double() / len(train_subset)\n",
    "    \n",
    "    \n",
    "    #   Validation Phase  \n",
    "    model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
    "    val_subset.dataset.transform = test_transform\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculations for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    epoch_val_loss = val_loss / len(val_subset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_subset)\n",
    "\n",
    "    val_subset.dataset.transform = train_transform\n",
    "    # Print epoch results\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} [{elapsed_time:.0f}s]')\n",
    "    print(f'  Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    print(f'  Val   Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Save the best model\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save checkpoint to disk\n",
    "        torch.save(model.state_dict(), 'best_model_cifar10.pth')\n",
    "        print(f'  New best model saved (Acc: {epoch_val_acc:.4f})')\n",
    "\n",
    "print(f\"\\nTraining complete. Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Load the best model weights back into the model\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"Best model weights loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fdb92-4fe9-4654-b517-a99394ca350c",
   "metadata": {},
   "source": [
    "### 4. Whole model Fine-Tuning\n",
    "\n",
    "To improve out model, we now need to \"unfreeze\" the entire model and let all 34 layers participate in training, but we will use a very small learning rate to avoid destroying the pre-trained knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27917083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights loaded, preparing for fine-tuning...\n",
      "Unfreezing all model layers...\n",
      "  Starting Fine-Tuning (LR=1e-05)  \n",
      "Fine-Tune Epoch 1/5 [298s]\n",
      "  Train Loss: 0.3372 Acc: 0.8831\n",
      "  Val   Loss: 0.1863 Acc: 0.9338\n",
      "  New best fine-tuned model saved (Acc: 0.9338)\n",
      "Fine-Tune Epoch 2/5 [310s]\n",
      "  Train Loss: 0.1839 Acc: 0.9362\n",
      "  Val   Loss: 0.1537 Acc: 0.9432\n",
      "  New best fine-tuned model saved (Acc: 0.9432)\n",
      "Fine-Tune Epoch 3/5 [309s]\n",
      "  Train Loss: 0.1310 Acc: 0.9544\n",
      "  Val   Loss: 0.1371 Acc: 0.9518\n",
      "  New best fine-tuned model saved (Acc: 0.9518)\n",
      "Fine-Tune Epoch 4/5 [313s]\n",
      "  Train Loss: 0.0991 Acc: 0.9658\n",
      "  Val   Loss: 0.1259 Acc: 0.9550\n",
      "  New best fine-tuned model saved (Acc: 0.9550)\n",
      "Fine-Tune Epoch 5/5 [304s]\n",
      "  Train Loss: 0.0748 Acc: 0.9748\n",
      "  Val   Loss: 0.1168 Acc: 0.9582\n",
      "  New best fine-tuned model saved (Acc: 0.9582)\n",
      "\n",
      "Fine-tuning complete. Final best validation accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "# Load the weights of the best model from the first phase\n",
    "model.load_state_dict(torch.load('best_model_cifar10.pth'))\n",
    "print(\"Best model weights loaded, preparing for fine-tuning...\")\n",
    "\n",
    "\n",
    "NUM_EPOCHS_FT = 5       # Train for a few more epochs\n",
    "LEARNING_RATE_FT = 1e-5 # MUST use a very small learning rate\n",
    "\n",
    "\n",
    "# 1. Unfreeze all layers\n",
    "print(\"Unfreezing all model layers...\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 2. Create a new optimizer to manage all parameters\n",
    "optimizer_ft = optim.AdamW(model.parameters(), lr=LEARNING_RATE_FT)\n",
    "\n",
    "# 3. Run the training and validation loop again\n",
    "print(f\"  Starting Fine-Tuning (LR={LEARNING_RATE_FT})  \")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_FT):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #   Training Phase  \n",
    "    model.train()\n",
    "    val_subset.dataset.transform = train_transform\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1) \n",
    "        loss.backward() # Gradients are now calculated for all layers\n",
    "        optimizer_ft.step() # All layers are updated\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_subset)\n",
    "    epoch_acc = running_corrects.double() / len(train_subset)\n",
    "    \n",
    "    #   Validation Phase  \n",
    "    model.eval()\n",
    "    val_subset.dataset.transform = test_transform\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    epoch_val_loss = val_loss / len(val_subset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_subset)\n",
    "\n",
    "    val_subset.dataset.transform = train_transform\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Fine-Tune Epoch {epoch+1}/{NUM_EPOCHS_FT} [{elapsed_time:.0f}s]')\n",
    "    print(f'  Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    print(f'  Val   Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Save the final fine-tuned model\n",
    "    if epoch_val_acc > best_val_acc: \n",
    "        best_val_acc = epoch_val_acc\n",
    "        torch.save(model.state_dict(), 'fine_tuned_best_model_cifar10.pth')\n",
    "        print(f'  New best fine-tuned model saved (Acc: {epoch_val_acc:.4f})')\n",
    "\n",
    "print(f\"\\nFine-tuning complete. Final best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d123a-8f26-45b9-95c3-956a1ac0b9bb",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Predict test dataset\n",
    "Using our previously trained and saved best model, run predictions on the test set (test_loader) and format the results as labels of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5c2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Test Set Evaluation ---\n",
      "Evaluation complete.\n",
      "\n",
      "Final Accuracy on Cifar-10 Test Set: 0.9559\n",
      "Total Correct: 9559 / 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n--- Starting Final Test Set Evaluation ---\")\n",
    "\n",
    "# 1. Load the best fine-tuned model\n",
    "model.load_state_dict(torch.load('fine_tuned_best_model_cifar10.pth'))\n",
    "model.eval() \n",
    "\n",
    "# 2. Loop over the test set (val_loader)\n",
    "test_corrects = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader: # `val_loader` 是我们的 Cifar-10 测试集\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Accumulate totals\n",
    "        total += labels.size(0)\n",
    "        test_corrects += torch.sum(preds == labels)\n",
    "\n",
    "# 3. Calculate final accuracy\n",
    "final_accuracy = test_corrects.double() / total\n",
    "print(\"Evaluation complete.\")\n",
    "print(f\"\\nFinal Accuracy on Cifar-10 Test Set: {final_accuracy:.4f}\")\n",
    "print(f\"Total Correct: {test_corrects} / {total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3-demo",
   "language": "python",
   "name": "chatglm3-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
