{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats\n",
    "\n",
    "\n",
    "This Notebook include:\n",
    "1.  Data preprocessing\n",
    "2.  Load train, validation and test datasets\n",
    "3.  Model define and training\n",
    "4.  Whole model Fine-Tuning\n",
    "5.  Predict test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing\n",
    "\n",
    "Define training transforms(with augmentaion) and validation transforms. This is because during testing, we want to evaluate the model's true performance on images that are \"original\" and consistent, rather than on randomly varied images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transforms defined successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define image size \n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Mean and std for ImageNet normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 1. Define transforms for training data (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),      # 1. Resize the image\n",
    "    transforms.RandomHorizontalFlip(),          # 2. Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(10),              # 3. Randomly rotate the image (+/- 10 degrees)\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), # 4. Apply slight color jitter\n",
    "    transforms.ToTensor(),                      # 5. Convert to PyTorch Tensor (scales to [0, 1])\n",
    "    transforms.Normalize(mean=mean, std=std)    # 6. Normalize the tensor\n",
    "])\n",
    "\n",
    "# 2. Define transforms for validation & test data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),      # 1. Resize the image\n",
    "    transforms.ToTensor(),                      # 2. Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=mean, std=std)    # 3. Normalize the tensor\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load train and validation datasets\n",
    "\n",
    "Creat two dataLoaders: one for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class mapping: {'cat': 0, 'dog': 1}\n",
      "Validation set class mapping: {'cat': 0, 'dog': 1}\n",
      "\n",
      "Successfully loaded 20000 training images and 5000 validation images.\n",
      "\n",
      "--- Checking DataLoader ---\n",
      "Image batch shape: torch.Size([64, 3, 224, 224])\n",
      "Label batch shape: torch.Size([64])\n",
      "Label examples (0=cat, 1=dog): tensor([0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Data Paths \n",
    "TRAIN_DIR = 'datasets/train'\n",
    "VAL_DIR = 'datasets/val'\n",
    "\n",
    "BATCH_SIZE = 64 \n",
    "\n",
    "# 2. Create Dataset Instances\n",
    "\n",
    "# Load the training set and apply training transforms\n",
    "train_dataset = ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "\n",
    "# Load the validation set and apply test transforms (no augmentation)\n",
    "val_dataset = ImageFolder(root=VAL_DIR, transform=test_transform)\n",
    "\n",
    "# 3. Check Labels\n",
    "# ImageFolder assigns labels alphabetically. 'cat' comes before 'dog'.\n",
    "print(f\"Training set class mapping: {train_dataset.class_to_idx}\")\n",
    "print(f\"Validation set class mapping: {val_dataset.class_to_idx}\")\n",
    "\n",
    "# 4. Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # Shuffle the training data\n",
    "    num_workers=4  # Use multiple processes to load data (set to 0 on Windows if errors occur)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, # Validation data does not need to be shuffled\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(train_dataset)} training images and {len(val_dataset)} validation images.\")\n",
    "\n",
    "# 5. Check one batch\n",
    "print(\"\\n  Checking DataLoader  \")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Image batch shape: {images.shape}\") # [BATCH_SIZE, 3, 224, 224]\n",
    "print(f\"Label batch shape: {labels.shape}\") # [BATCH_SIZE]\n",
    "print(f\"Label examples (0=cat, 1=dog): {labels[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load test datasets\n",
    "\n",
    "Thus `test` folder is flat (e.g., `test/1.jpg`, `test/2.jpg`) and has no tags. For this case, we still need a simple custom `Dataset` to load the images and extract their IDs (for the final commit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestImageDataset class defined successfully.\n"
     ]
    }
   ],
   "source": [
    "class TestImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading the test set, which has a flat structure\n",
    "    (e.g., test/1.jpg, test/2.jpg ...).\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Assume all test images are .jpg format\n",
    "        self.file_paths = glob.glob(os.path.join(self.root_dir, '*.jpg'))\n",
    "        # Sort paths by ID (1.jpg, 2.jpg, ...), ensuring correct submission order\n",
    "        self.file_paths.sort(key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of test images\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image path for the given index\n",
    "        img_path = self.file_paths[idx]\n",
    "        \n",
    "        # Load the image (using PIL) and convert to RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply the pre-processing transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Extract the image ID from the filename (e.g., '.../test/123.jpg' -> 123)\n",
    "        img_id = int(os.path.basename(img_path).split('.')[0])\n",
    "        \n",
    "        # Return the processed image and its ID\n",
    "        return image, img_id\n",
    "\n",
    "print(\"TestImageDataset class defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 500 test images.\n",
      "\n",
      "--- Checking Test Loader ---\n",
      "Test image batch shape: torch.Size([64, 3, 224, 224])\n",
      "Test image ID shape: torch.Size([64])\n",
      "Test image ID examples: tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#  1. Define Test Path \n",
    "# !!! Make sure this matches your folder name !!!\n",
    "TEST_DIR = 'datasets/test'\n",
    "# TEST_DIR = 'datasets/test12500'\n",
    "\n",
    "try:\n",
    "    #  2. Create Test Dataset \n",
    "    # Use the custom TestImageDataset defined earlier\n",
    "    test_dataset = TestImageDataset(root_dir=TEST_DIR, transform=test_transform)\n",
    "    \n",
    "    if len(test_dataset) > 0:\n",
    "        #   3. Create Test DataLoader  \n",
    "        test_loader = DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=BATCH_SIZE, # Can re-use the BATCH_SIZE from training\n",
    "            shuffle=False,      # CRITICAL: Never shuffle the test set!\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nSuccessfully loaded {len(test_dataset)} test images.\")\n",
    "        \n",
    "        #   4. Check one batch  \n",
    "        print(\"\\n  Checking Test Loader  \")\n",
    "        images, ids = next(iter(test_loader))\n",
    "        print(f\"Test image batch shape: {images.shape}\")\n",
    "        print(f\"Test image ID shape: {ids.shape}\")\n",
    "        print(f\"Test image ID examples: {ids[:5]}\")\n",
    "    else:\n",
    "        print(f\"Warning: No .jpg files found in '{TEST_DIR}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Test path '{TEST_DIR}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bc329",
   "metadata": {},
   "source": [
    "### 4. Model define and training\n",
    "During the model training phase, we used transfer learning, loading a pre-trained ResNet-34 model. We trained only the last layer of this pre-trained model (ResNet-34) to quickly complete the cat and dog classification task. The code loops 10 times, evaluating the performance with a validation set after each loop, and finally saving the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e6ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Class mapping: {'cat': 0, 'dog': 1}\n",
      "\n",
      "--- Starting Training (Feature Extraction) ---\n",
      "Epoch 1/10 [24s]\n",
      "  Train Loss: 0.1618 Acc: 0.9534\n",
      "  Val   Loss: 0.0778 Acc: 0.9746\n",
      "  New best model saved (Acc: 0.9746)\n",
      "Epoch 2/10 [25s]\n",
      "  Train Loss: 0.0807 Acc: 0.9722\n",
      "  Val   Loss: 0.0610 Acc: 0.9796\n",
      "  New best model saved (Acc: 0.9796)\n",
      "Epoch 3/10 [25s]\n",
      "  Train Loss: 0.0716 Acc: 0.9738\n",
      "  Val   Loss: 0.0545 Acc: 0.9810\n",
      "  New best model saved (Acc: 0.9810)\n",
      "Epoch 4/10 [25s]\n",
      "  Train Loss: 0.0654 Acc: 0.9761\n",
      "  Val   Loss: 0.0508 Acc: 0.9824\n",
      "  New best model saved (Acc: 0.9824)\n",
      "Epoch 5/10 [25s]\n",
      "  Train Loss: 0.0616 Acc: 0.9766\n",
      "  Val   Loss: 0.0505 Acc: 0.9816\n",
      "Epoch 6/10 [25s]\n",
      "  Train Loss: 0.0588 Acc: 0.9787\n",
      "  Val   Loss: 0.0487 Acc: 0.9826\n",
      "  New best model saved (Acc: 0.9826)\n",
      "Epoch 7/10 [24s]\n",
      "  Train Loss: 0.0577 Acc: 0.9768\n",
      "  Val   Loss: 0.0485 Acc: 0.9830\n",
      "  New best model saved (Acc: 0.9830)\n",
      "Epoch 8/10 [24s]\n",
      "  Train Loss: 0.0586 Acc: 0.9777\n",
      "  Val   Loss: 0.0479 Acc: 0.9844\n",
      "  New best model saved (Acc: 0.9844)\n",
      "Epoch 9/10 [24s]\n",
      "  Train Loss: 0.0559 Acc: 0.9785\n",
      "  Val   Loss: 0.0468 Acc: 0.9842\n",
      "Epoch 10/10 [24s]\n",
      "  Train Loss: 0.0579 Acc: 0.9777\n",
      "  Val   Loss: 0.0593 Acc: 0.9756\n",
      "\n",
      "Training complete. Best validation accuracy: 0.9844\n",
      "Best model weights loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# 1. Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Load pre-trained model (ResNet-34)\n",
    "# Download ResNet-34 with weights pre-trained on ImageNet\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 3. Freeze all pre-trained layers\n",
    "# Set requires_grad = False to stop gradients from flowing to these layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 4. Replace the final layer (classifier)\n",
    "# Get the number of input features for the original final layer ('fc')\n",
    "num_ftrs = model.fc.in_features \n",
    "\n",
    "# Replace it with a new Linear layer\n",
    "# Output features = 1 (for binary classification: 0=cat, 1=dog)\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Move the new model structure to the selected device (GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Define Loss Function and Optimizer\n",
    "# Loss Function: BCEWithLogitsLoss\n",
    "# This is ideal for binary classification. It combines a Sigmoid layer\n",
    "# with Binary Cross Entropy loss for better numerical stability.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer: Adam\n",
    "# IMPORTANT: We only pass the parameters of the new final layer\n",
    "# to the optimizer. Only this layer will be trained.\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Get the class index mapping (from the previous cell) for reference\n",
    "# We expect {'cat': 0, 'dog': 1}\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(f\"Class mapping: {class_to_idx}\")\n",
    "\n",
    "\n",
    "# 6. Training and Validation Loop\n",
    "NUM_EPOCHS = 10 # Number of times to loop through the entire training dataset\n",
    "best_val_acc = 0.0 # Track the best validation accuracy achieved\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Track the weights of the best model\n",
    "\n",
    "print(\"\\n  Starting Training (Feature Extraction)  \")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #   Training Phase  \n",
    "    model.train() # Set model to training mode (enables dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Move data and labels to the GPU\n",
    "        inputs = inputs.to(device)\n",
    "        # Reshape labels to [BATCH_SIZE, 1] and type float for the loss function\n",
    "        labels = labels.float().view(-1, 1).to(device) \n",
    "        \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: get raw model output (logits)\n",
    "        outputs = model(inputs) \n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate predictions (0 or 1)\n",
    "        # 1. Apply sigmoid to logits (0 to 1 probability)\n",
    "        # 2. Threshold at 0.5 to get True/False\n",
    "        # 3. Convert to float (0.0 or 1.0)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float() \n",
    "        \n",
    "        # Backpropagation (calculate gradients)\n",
    "        loss.backward()\n",
    "        # Update optimizer (only for model.fc weights)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate statistics for this epoch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    \n",
    "    #   Validation Phase  \n",
    "    model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculations for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().view(-1, 1).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_dataset)\n",
    "    \n",
    "    # Print epoch results\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} [{elapsed_time:.0f}s]')\n",
    "    print(f'  Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    print(f'  Val   Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Save the best model\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save checkpoint to disk\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'  New best model saved (Acc: {epoch_val_acc:.4f})')\n",
    "\n",
    "print(f\"\\nTraining complete. Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Load the best model weights back into the model\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"Best model weights loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c76f9a",
   "metadata": {},
   "source": [
    "### 5. Whole model Fine-Tuning\n",
    "\n",
    "To improve out model, we now need to \"unfreeze\" the entire model and let all 34 layers participate in training, but we will use a very small learning rate to avoid destroying the pre-trained knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27917083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights loaded, preparing for fine-tuning...\n",
      "Unfreezing all model layers...\n",
      "--- Starting Fine-Tuning (LR=1e-05) ---\n",
      "Fine-Tune Epoch 1/5 [63s]\n",
      "  Train Loss: 0.0427 Acc: 0.9841\n",
      "  Val   Loss: 0.0285 Acc: 0.9906\n",
      "Fine-Tune Epoch 2/5 [64s]\n",
      "  Train Loss: 0.0235 Acc: 0.9916\n",
      "  Val   Loss: 0.0271 Acc: 0.9912\n",
      "  New best fine-tuned model saved (Acc: 0.9912)\n",
      "Fine-Tune Epoch 3/5 [63s]\n",
      "  Train Loss: 0.0140 Acc: 0.9953\n",
      "  Val   Loss: 0.0267 Acc: 0.9908\n",
      "Fine-Tune Epoch 4/5 [63s]\n",
      "  Train Loss: 0.0103 Acc: 0.9964\n",
      "  Val   Loss: 0.0271 Acc: 0.9908\n",
      "Fine-Tune Epoch 5/5 [63s]\n",
      "  Train Loss: 0.0098 Acc: 0.9970\n",
      "  Val   Loss: 0.0257 Acc: 0.9916\n",
      "  New best fine-tuned model saved (Acc: 0.9916)\n",
      "\n",
      "Fine-tuning complete. Final best validation accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "# Load the weights of the best model from the first phase\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Best model weights loaded, preparing for fine-tuning...\")\n",
    "\n",
    "\n",
    "NUM_EPOCHS_FT = 5       # Train for a few more epochs\n",
    "LEARNING_RATE_FT = 1e-5 # MUST use a very small learning rate\n",
    "\n",
    "\n",
    "# 1. Unfreeze all layers\n",
    "print(\"Unfreezing all model layers...\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 2. Create a new optimizer to manage all parameters\n",
    "optimizer_ft = optim.AdamW(model.parameters(), lr=LEARNING_RATE_FT)\n",
    "\n",
    "# 3. Run the training and validation loop again\n",
    "print(f\"  Starting Fine-Tuning (LR={LEARNING_RATE_FT})  \")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_FT):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #   Training Phase  \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().view(-1, 1).to(device) \n",
    "        \n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float() \n",
    "        loss.backward() # Gradients are now calculated for all layers\n",
    "        optimizer_ft.step() # All layers are updated\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    #   Validation Phase  \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().view(-1, 1).to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_dataset)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Fine-Tune Epoch {epoch+1}/{NUM_EPOCHS_FT} [{elapsed_time:.0f}s]')\n",
    "    print(f'  Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    print(f'  Val   Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Save the final fine-tuned model\n",
    "    if epoch_val_acc > best_val_acc: \n",
    "        best_val_acc = epoch_val_acc\n",
    "        torch.save(model.state_dict(), 'fine_tuned_best_model.pth')\n",
    "        print(f'  New best fine-tuned model saved (Acc: {epoch_val_acc:.4f})')\n",
    "\n",
    "print(f\"\\nFine-tuning complete. Final best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddb24c",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Predict test dataset\n",
    "Using our previously trained and saved best model, run predictions on the test set (test_loader) and format the results as labels of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f5c2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting predictions on the test set ---\n",
      "Predictions complete.\n",
      "\n",
      "Successfully created 'submission.csv'.\n",
      "File preview:\n",
      "   id  label\n",
      "0   1      0\n",
      "1   2      0\n",
      "2   3      0\n",
      "3   4      1\n",
      "4   5      1\n",
      "\n",
      "Total rows: 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "results = [] # List to store (id, label) pairs\n",
    "# Class indices { 'cat': 0, 'dog': 1 }\n",
    "if class_to_idx.get('dog') != 1 or class_to_idx.get('cat') != 0:\n",
    "    print(\"Warning: Class indices do not match expected (cat=0, dog=1)!\")\n",
    "    print(f\"Current indices: {class_to_idx}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Starting predictions on the test set ---\")\n",
    "\n",
    "# 2. Prediction Loop\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:\n",
    "        # Move images to the GPU\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass: get raw model outputs (logits)\n",
    "        outputs = model(images) # Shape: [Batch, 1]\n",
    "        \n",
    "        # --- NOTE: This block generates 0/1 integer labels ---\n",
    "        # --- This is BAD for LogLoss competitions ---\n",
    "        \n",
    "        # Convert logits to probabilities (0.0 to 1.0)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to 0 or 1 predictions\n",
    "        # (probs > 0.5) creates a boolean (True/False) tensor\n",
    "        # .int() converts True -> 1 and False -> 0\n",
    "        preds = (probs > 0.5).int() \n",
    "        \n",
    "        # Move prediction tensor from GPU to CPU ( .cpu() ) and convert to a list\n",
    "        preds_list = preds.view(-1).cpu().tolist()\n",
    "        \n",
    "        # Store the (ID, Label) pairs\n",
    "        for img_id, label in zip(ids, preds_list):\n",
    "            results.append({\n",
    "                \"id\": int(img_id), # Ensure ID is an integer\n",
    "                \"label\": label     # The predicted label (0 or 1)\n",
    "            })\n",
    "\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "# 3. Create Submission File\n",
    "if len(results) > 0:\n",
    "    # Convert the results list to a pandas DataFrame\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    \n",
    "    submission_df = submission_df.sort_values(by=\"id\")\n",
    "    \n",
    "    # Save to a .csv file\n",
    "    # index=False prevents pandas from writing an extra index column\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully created 'submission.csv'.\")\n",
    "    print(\"File preview:\")\n",
    "    print(submission_df.head()) # Print the first 5 rows\n",
    "    print(f\"\\nTotal rows: {len(submission_df)}\")\n",
    "\n",
    "else:\n",
    "    print(\"No predictions were generated. Check your test_loader.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1588f",
   "metadata": {},
   "source": [
    "### 7. Predict test dataset with probability\n",
    "\n",
    "We need to modify cell 6 to output the raw probability instead of the 0/1 label. This is because the Kaggle competition requires submitting the \"probability of being a dog,\" allowing us to assess the accuracy of our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc1286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting predictions on test set (generating probabilities) ---\n",
      "Predictions complete.\n",
      "\n",
      "Successfully created 'submission_with_probs.csv'.\n",
      "File preview (note 'label' column now contains probabilities):\n",
      "   id  label\n",
      "0   1  0.005\n",
      "1   2  0.005\n",
      "2   3  0.005\n",
      "3   4  0.995\n",
      "4   5  0.995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "\n",
    "print(\"\\n--- Starting predictions on test set (generating probabilities) ---\")\n",
    "\n",
    "# 1. Prediction Loop \n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get raw model outputs (logits)\n",
    "        outputs = model(images) # Shape: [Batch, 1]\n",
    "        \n",
    "        # --- CRITICAL CHANGE for LogLoss ---\n",
    "        # 1. Do NOT convert to 0/1\n",
    "        # 2. Submit the raw probability\n",
    "        # Apply sigmoid to convert logits to probabilities (0.0 to 1.0)\n",
    "        probs = torch.sigmoid(outputs) \n",
    "        \n",
    "        # Move probabilities from GPU back to CPU\n",
    "        probs_list = probs.view(-1).cpu().tolist()\n",
    "        \n",
    "        # Store (ID, Probability) pairs\n",
    "        for img_id, probability in zip(ids, probs_list):\n",
    "            results.append({\n",
    "                \"id\": int(img_id),\n",
    "                \"label\": probability  # The 'label' is now a float, e.g., 0.983 or 0.012\n",
    "            })\n",
    "\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "# 2. Create Submission File ---\n",
    "submission_df = pd.DataFrame(results)\n",
    "submission_df = submission_df.sort_values(by=\"id\")\n",
    "\n",
    "# --- CRITICAL: LogLoss Trap Protection! ---\n",
    "# LogLoss is infinite at exactly 0 or 1.\n",
    "# We must \"clip\" our probabilities to a safe range, e.g., [0.005, 0.995]\n",
    "submission_df['label'] = submission_df['label'].clip(0.005, 0.995)\n",
    "\n",
    "# 3.Save the final CSV file\n",
    "submission_df.to_csv(\"submission_with_probs.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully created 'submission_with_probs.csv'.\")\n",
    "print(\"File preview (note 'label' column now contains probabilities):\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
